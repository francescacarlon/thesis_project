{
  "1": {
    "tailored_texts": {
      "mistral": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8153522610664368,
            "hallucination_avg": 4.8,
            "token_count": 267
          },
          "prompt2": {
            "cosine_similarity": 0.9181023836135864,
            "hallucination_avg": 4.7,
            "token_count": 271
          },
          "prompt3": {
            "cosine_similarity": 0.9068188071250916,
            "hallucination_avg": 4.4,
            "token_count": 216
          },
          "prompt4": {
            "cosine_similarity": 0.9225825071334839,
            "hallucination_avg": 4.7,
            "token_count": 186
          },
          "prompt5": {
            "cosine_similarity": 0.8517158627510071,
            "hallucination_avg": 4.7,
            "token_count": 225
          }
        }
      },
      "llama": {
        "CS": {
          "prompt3": {
            "cosine_similarity": 0.8156543970108032,
            "hallucination_avg": 4.6,
            "token_count": 390
          }
        }
      },
      "gpt4o": {
        "CS": {
          "prompt2": {
            "cosine_similarity": 0.8687797784805298,
            "hallucination_avg": 4.9,
            "token_count": 225
          },
          "prompt4": {
            "cosine_similarity": 0.8722004294395447,
            "hallucination_avg": 5.0,
            "token_count": 161
          },
          "prompt5": {
            "cosine_similarity": 0.8682388663291931,
            "hallucination_avg": 4.2,
            "token_count": 232
          }
        }
      }
    }
  },
  "2": {
    "tailored_texts": {
      "mistral": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.9449005126953125,
            "hallucination_avg": 4.3,
            "token_count": 221
          },
          "prompt2": {
            "cosine_similarity": 0.952573835849762,
            "hallucination_avg": 5.0,
            "token_count": 257
          },
          "prompt3": {
            "cosine_similarity": 0.9251545667648315,
            "hallucination_avg": 4.8,
            "token_count": 280
          },
          "prompt4": {
            "cosine_similarity": 0.9170640707015991,
            "hallucination_avg": 4.55,
            "token_count": 216
          },
          "prompt5": {
            "cosine_similarity": 0.9754759073257446,
            "hallucination_avg": 5.0,
            "token_count": 256
          }
        }
      },
      "llama": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.9069540500640869,
            "hallucination_avg": 4.6,
            "token_count": 403
          },
          "prompt2": {
            "cosine_similarity": 0.8814425468444824,
            "hallucination_avg": 4.2,
            "token_count": 487
          },
          "prompt3": {
            "cosine_similarity": 0.917875349521637,
            "hallucination_avg": 4.9,
            "token_count": 483
          }
        }
      },
      "gpt4o": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.9382408857345581,
            "hallucination_avg": 4.9,
            "token_count": 258
          },
          "prompt2": {
            "cosine_similarity": 0.9450578093528748,
            "hallucination_avg": 4.95,
            "token_count": 251
          },
          "prompt3": {
            "cosine_similarity": 0.8995142579078674,
            "hallucination_avg": 4.7,
            "token_count": 322
          },
          "prompt4": {
            "cosine_similarity": 0.9377381801605225,
            "hallucination_avg": 5.0,
            "token_count": 186
          },
          "prompt5": {
            "cosine_similarity": 0.9204601645469666,
            "hallucination_avg": 4.6,
            "token_count": 280
          }
        }
      },
      "claude": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8069146275520325,
            "hallucination_avg": 4.5,
            "token_count": 219
          },
          "prompt2": {
            "cosine_similarity": 0.8867177963256836,
            "hallucination_avg": 4.6,
            "token_count": 244
          },
          "prompt3": {
            "cosine_similarity": 0.839339017868042,
            "hallucination_avg": 4.8,
            "token_count": 277
          },
          "prompt4": {
            "cosine_similarity": 0.8151059150695801,
            "hallucination_avg": 4.3,
            "token_count": 240
          },
          "prompt5": {
            "cosine_similarity": 0.822647213935852,
            "hallucination_avg": 4.5,
            "token_count": 240
          }
        }
      },
      "deepseek": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8134670257568359,
            "hallucination_avg": 4.7,
            "token_count": 182
          },
          "prompt2": {
            "cosine_similarity": 0.8282610177993774,
            "hallucination_avg": 4.5,
            "token_count": 146
          },
          "prompt3": {
            "cosine_similarity": 0.8565070033073425,
            "hallucination_avg": 4.2,
            "token_count": 175
          },
          "prompt4": {
            "cosine_similarity": 0.8532506227493286,
            "hallucination_avg": 4.2,
            "token_count": 130
          },
          "prompt5": {
            "cosine_similarity": 0.8011308908462524,
            "hallucination_avg": 4.5,
            "token_count": 186
          }
        }
      }
    }
  },
  "3": {
    "tailored_texts": {
      "mistral": {
        "CS": {
          "prompt3": {
            "cosine_similarity": 0.8803181052207947,
            "hallucination_avg": 4.95,
            "token_count": 187
          },
          "prompt4": {
            "cosine_similarity": 0.8980931639671326,
            "hallucination_avg": 4.2,
            "token_count": 250
          },
          "prompt5": {
            "cosine_similarity": 0.9079538583755493,
            "hallucination_avg": 4.7,
            "token_count": 168
          }
        }
      },
      "gpt4o": {
        "CS": {
          "prompt3": {
            "cosine_similarity": 0.813031017780304,
            "hallucination_avg": 4.5,
            "token_count": 320
          },
          "prompt4": {
            "cosine_similarity": 0.8472038507461548,
            "hallucination_avg": 4.4,
            "token_count": 232
          }
        }
      },
      "claude": {},
      "deepseek": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8205076456069946,
            "hallucination_avg": 4.8,
            "token_count": 159
          }
        }
      }
    }
  },
  "4": {
    "tailored_texts": {
      "mistral": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8484218120574951,
            "hallucination_avg": 4.8,
            "token_count": 224
          },
          "prompt4": {
            "cosine_similarity": 0.9003214836120605,
            "hallucination_avg": 4.9,
            "token_count": 191
          },
          "prompt5": {
            "cosine_similarity": 0.8777247667312622,
            "hallucination_avg": 4.8,
            "token_count": 184
          }
        }
      },
      "llama": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8411433696746826,
            "hallucination_avg": 4.9,
            "token_count": 360
          },
          "prompt5": {
            "cosine_similarity": 0.8244737386703491,
            "hallucination_avg": 4.7,
            "token_count": 260
          }
        }
      },
      "gpt4o": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8802945613861084,
            "hallucination_avg": 5.0,
            "token_count": 224
          },
          "prompt4": {
            "cosine_similarity": 0.8923216462135315,
            "hallucination_avg": 5.0,
            "token_count": 146
          }
        }
      }
    }
  },
  "5": {
    "tailored_texts": {
      "mistral": {
        "CS": {
          "prompt1": {
            "cosine_similarity": 0.8298665881156921,
            "hallucination_avg": 4.75,
            "token_count": 198
          },
          "prompt2": {
            "cosine_similarity": 0.8436535000801086,
            "hallucination_avg": 4.9,
            "token_count": 210
          },
          "prompt3": {
            "cosine_similarity": 0.847260594367981,
            "hallucination_avg": 4.7,
            "token_count": 198
          },
          "prompt4": {
            "cosine_similarity": 0.8559238910675049,
            "hallucination_avg": 4.7,
            "token_count": 199
          },
          "prompt5": {
            "cosine_similarity": 0.8655133247375488,
            "hallucination_avg": 5.0,
            "token_count": 223
          }
        }
      },
      "gpt4o": {
        "CS": {
          "prompt2": {
            "cosine_similarity": 0.822360634803772,
            "hallucination_avg": 4.8,
            "token_count": 310
          }
        }
      }
    }
  },
  "6": {
    "tailored_texts": {
      "mistral": {
        "L": {
          "prompt3": {
            "cosine_similarity": 0.8470892906188965,
            "hallucination_avg": 5.0,
            "token_count": 203
          },
          "prompt4": {
            "cosine_similarity": 0.8939213752746582,
            "hallucination_avg": 4.8,
            "token_count": 292
          }
        }
      },
      "gpt4o": {}
    }
  },
  "7": {
    "tailored_texts": {
      "mistral": {
        "L": {
          "prompt2": {
            "cosine_similarity": 0.8275209665298462,
            "hallucination_avg": 5.0,
            "token_count": 201
          },
          "prompt3": {
            "cosine_similarity": 0.8169453740119934,
            "hallucination_avg": 5.0,
            "token_count": 215
          },
          "prompt4": {
            "cosine_similarity": 0.8082410097122192,
            "hallucination_avg": 5.0,
            "token_count": 181
          }
        }
      }
    }
  },
  "8": {
    "tailored_texts": {
      "mistral": {
        "L": {
          "prompt1": {
            "cosine_similarity": 0.8322855234146118,
            "hallucination_avg": 4.3,
            "token_count": 309
          },
          "prompt2": {
            "cosine_similarity": 0.8036302328109741,
            "hallucination_avg": 4.7,
            "token_count": 246
          },
          "prompt3": {
            "cosine_similarity": 0.885465681552887,
            "hallucination_avg": 5.0,
            "token_count": 214
          },
          "prompt4": {
            "cosine_similarity": 0.8798613548278809,
            "hallucination_avg": 5.0,
            "token_count": 223
          },
          "prompt5": {
            "cosine_similarity": 0.9102436304092407,
            "hallucination_avg": 5.0,
            "token_count": 226
          }
        }
      },
      "gpt4o": {}
    }
  },
  "9": {
    "tailored_texts": {
      "mistral": {
        "L": {
          "prompt1": {
            "cosine_similarity": 0.9185652732849121,
            "hallucination_avg": 4.5,
            "token_count": 278
          },
          "prompt2": {
            "cosine_similarity": 0.8964722156524658,
            "hallucination_avg": 4.9,
            "token_count": 276
          },
          "prompt3": {
            "cosine_similarity": 0.9138847589492798,
            "hallucination_avg": 5.0,
            "token_count": 190
          },
          "prompt4": {
            "cosine_similarity": 0.8371784687042236,
            "hallucination_avg": 5.0,
            "token_count": 220
          },
          "prompt5": {
            "cosine_similarity": 0.8323479294776917,
            "hallucination_avg": 4.5,
            "token_count": 407
          }
        }
      },
      "llama": {},
      "gpt4o": {
        "L": {
          "prompt1": {
            "cosine_similarity": 0.8634300231933594,
            "hallucination_avg": 5.0,
            "token_count": 290
          },
          "prompt3": {
            "cosine_similarity": 0.827786922454834,
            "hallucination_avg": 4.45,
            "token_count": 302
          },
          "prompt5": {
            "cosine_similarity": 0.8369871377944946,
            "hallucination_avg": 4.3,
            "token_count": 254
          }
        }
      }
    }
  },
  "10": {
    "tailored_texts": {
      "mistral": {
        "L": {
          "prompt1": {
            "cosine_similarity": 0.8672769069671631,
            "hallucination_avg": 4.9,
            "token_count": 450
          },
          "prompt2": {
            "cosine_similarity": 0.875806450843811,
            "hallucination_avg": 4.9,
            "token_count": 272
          },
          "prompt3": {
            "cosine_similarity": 0.9429935812950134,
            "hallucination_avg": 5.0,
            "token_count": 237
          },
          "prompt4": {
            "cosine_similarity": 0.9057005643844604,
            "hallucination_avg": 4.8,
            "token_count": 249
          },
          "prompt5": {
            "cosine_similarity": 0.8381253480911255,
            "hallucination_avg": 4.9,
            "token_count": 215
          }
        }
      },
      "llama": {
        "L": {
          "prompt4": {
            "cosine_similarity": 0.8173843622207642,
            "hallucination_avg": 4.75,
            "token_count": 125
          }
        }
      },
      "gpt4o": {
        "L": {
          "prompt2": {
            "cosine_similarity": 0.8235943913459778,
            "hallucination_avg": 4.9,
            "token_count": 284
          }
        }
      }
    }
  }
}